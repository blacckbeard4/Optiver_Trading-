# ğŸ§ ğŸ“ˆ Optiver - Trading at the Close: GRU-based Price Movement Forecasting

Welcome to my solution for the [Optiver: Trading at the Close](https://www.kaggle.com/competitions/optiver-trading-at-the-close) Kaggle competition.

In this high-stakes prediction challenge, the goal is to forecast **auction price movements** of stocks using ultra-high-frequency order book and auction data â€” a real-world, time-critical trading scenario.

This project uses a **GRU-based deep learning model** integrated with **Polars for lightning-fast data processing**, and fine-tuned using **Optuna**. The final solution is compatible with Kaggleâ€™s **live prediction API**.

---
 <p align="center">
  <img src="https://i.imgur.com/SuYWQ6e.png" width="500">

## ğŸ¯ Objective

Forecast a stockâ€™s **final auction price movement** using historical features extracted from:
- Order book snapshots
- Auction and transaction history
- Time-series derived metrics

ğŸ“ Evaluation Metric: **Mean Absolute Error (MAE)**  
ğŸ¯ Target: `target = wap - reference_price`

---
### ğŸ¯ Target Distribution

 <p align="center">
  <img src="https://i.imgur.com/B1aVk13.png" width="500">
  
---

## ğŸ§± Pipeline Overview

| Stage                      | Description |
|---------------------------|-------------|
| ğŸ“¦ **Data Loading**        | Loaded 100M+ rows with `Polars` for speed and memory efficiency |
| ğŸ§¹ **Cleaning & Imputation** | Dropped `near_price`, `far_price`, handled nulls & infinities |
| ğŸ“Š **Feature Engineering** | Custom price/spread/imbalance metrics, slopes, lags, and volatility |
| ğŸ§© **Sequence Modeling**   | GRU (Gated Recurrent Unit) with PackedSequence & variable time steps |
| ğŸ§ª **Hyperparameter Tuning** | Used Optuna for optimizing GRU depth, dropout, learning rate, etc. |
| ğŸš€ **Live Submission**     | Compatible with `optiver2023.iter_test()` for real-time evaluation |

---

## ğŸ§  Model Architecture

- Input: Normalized sequences of engineered features
- Model: Multi-layer GRU + dense head
- Loss: `SmoothL1Loss` for robustness
- Optimizer: AdamW

<!-- Optional image -->
<!-- <p align="center">
  <img src="images/gru_model.png" width="400">
</p> -->

---

## ğŸ§ª Evaluation Snapshot

| Model            | MAE (CV) | MAE (LB) | Notes                            |
|------------------|----------|----------|----------------------------------|
| GRU + Polars     | 0.00132  | 0.00138  | Tuned with full engineered set   |

---


## ğŸ› ï¸ Tech Stack

- `Polars` â€“ ultra-fast dataframe ops for time series
- `PyTorch` â€“ custom GRU with Packed Sequences
- `Optuna` â€“ Bayesian hyperparameter optimization
- `Matplotlib`, `Seaborn` â€“ EDA & performance visuals
- `Kaggle API` â€“ live evaluation loop

---

## ğŸ§  Key Learnings

- Data pipelines matter: **Polars > pandas** for scale.
- **GRU is ideal for sparse, autocorrelated time-series** problems.
- **Auto-tuning beats intuition** for hyperparameters.
- Designing for **live inference compatibility** from day 1 saves time later.

---

## ğŸ“¬ Contact

Made with ğŸ’¹ by [Justin Varghese](https://github.com/blacckbeard4)  
Letâ€™s connect if you're into **ML for finance**, **streaming analytics**, or **Kaggle problem-solving**.

---
